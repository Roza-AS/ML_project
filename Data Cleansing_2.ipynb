{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efca6d3-f0bc-4fd6-aeb6-65c61211d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3.2 - Data imputation & Encoding\n",
    "'''\n",
    "In this notebook we are going to handle missing data, by imputing missing data via median/mode..\n",
    "also, we are going to encode via one-hot encoding or dummy encoding  variable so that the predictive model can process and use them.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e8c8d5-e602-45d3-9c83-5299760d5324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81717944-c372-4315-8845-09fa48d21c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>End_Year</th>\n",
       "      <th>End_Month</th>\n",
       "      <th>End_Day</th>\n",
       "      <th>End_DayOfWeek</th>\n",
       "      <th>End_Hour</th>\n",
       "      <th>End_Minute</th>\n",
       "      <th>End_Second</th>\n",
       "      <th>End_IsWeekend</th>\n",
       "      <th>Duration_Minutes</th>\n",
       "      <th>Duration_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 05:46:00</td>\n",
       "      <td>2016-02-08 11:00:00</td>\n",
       "      <td>39.865147</td>\n",
       "      <td>-84.058723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>5.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:07:59</td>\n",
       "      <td>2016-02-08 06:37:59</td>\n",
       "      <td>39.928059</td>\n",
       "      <td>-82.831184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:49:27</td>\n",
       "      <td>2016-02-08 07:19:27</td>\n",
       "      <td>39.063148</td>\n",
       "      <td>-84.032608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 07:23:34</td>\n",
       "      <td>2016-02-08 07:53:34</td>\n",
       "      <td>39.747753</td>\n",
       "      <td>-84.205582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A5</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 07:39:07</td>\n",
       "      <td>2016-02-08 08:09:07</td>\n",
       "      <td>39.627781</td>\n",
       "      <td>-84.188354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Source Severity          Start_Time            End_Time  Start_Lat  \\\n",
       "0  A1  Source2        3 2016-02-08 05:46:00 2016-02-08 11:00:00  39.865147   \n",
       "1  A2  Source2        2 2016-02-08 06:07:59 2016-02-08 06:37:59  39.928059   \n",
       "2  A3  Source2        2 2016-02-08 06:49:27 2016-02-08 07:19:27  39.063148   \n",
       "3  A4  Source2        3 2016-02-08 07:23:34 2016-02-08 07:53:34  39.747753   \n",
       "4  A5  Source2        2 2016-02-08 07:39:07 2016-02-08 08:09:07  39.627781   \n",
       "\n",
       "   Start_Lng  End_Lat  End_Lng  Distance(mi)  ... End_Year End_Month End_Day  \\\n",
       "0 -84.058723      NaN      NaN          0.01  ...   2016.0       2.0     8.0   \n",
       "1 -82.831184      NaN      NaN          0.01  ...   2016.0       2.0     8.0   \n",
       "2 -84.032608      NaN      NaN          0.01  ...   2016.0       2.0     8.0   \n",
       "3 -84.205582      NaN      NaN          0.01  ...   2016.0       2.0     8.0   \n",
       "4 -84.188354      NaN      NaN          0.01  ...   2016.0       2.0     8.0   \n",
       "\n",
       "  End_DayOfWeek End_Hour End_Minute End_Second End_IsWeekend Duration_Minutes  \\\n",
       "0           0.0     11.0        0.0        0.0             0            314.0   \n",
       "1           0.0      6.0       37.0       59.0             0             30.0   \n",
       "2           0.0      7.0       19.0       27.0             0             30.0   \n",
       "3           0.0      7.0       53.0       34.0             0             30.0   \n",
       "4           0.0      8.0        9.0        7.0             0             30.0   \n",
       "\n",
       "  Duration_Hours  \n",
       "0       5.233333  \n",
       "1       0.500000  \n",
       "2       0.500000  \n",
       "3       0.500000  \n",
       "4       0.500000  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now to data imputation\n",
    "\n",
    "df = pd.read_pickle('df_cleaned_with_outliers.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f958ecb-0efa-4211-9225-7ae08b82c533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7728394 entries, 0 to 7728393\n",
      "Data columns (total 64 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   ID                     string        \n",
      " 1   Source                 category      \n",
      " 2   Severity               category      \n",
      " 3   Start_Time             datetime64[ns]\n",
      " 4   End_Time               datetime64[ns]\n",
      " 5   Start_Lat              float64       \n",
      " 6   Start_Lng              float64       \n",
      " 7   End_Lat                float64       \n",
      " 8   End_Lng                float64       \n",
      " 9   Distance(mi)           float64       \n",
      " 10  Description            string        \n",
      " 11  Street                 string        \n",
      " 12  City                   string        \n",
      " 13  County                 string        \n",
      " 14  State                  string        \n",
      " 15  Zipcode                string        \n",
      " 16  Country                string        \n",
      " 17  Timezone               string        \n",
      " 18  Airport_Code           string        \n",
      " 19  Weather_Timestamp      datetime64[ns]\n",
      " 20  Temperature(F)         float64       \n",
      " 21  Wind_Chill(F)          float64       \n",
      " 22  Humidity(%)            float64       \n",
      " 23  Pressure(in)           float64       \n",
      " 24  Visibility(mi)         float64       \n",
      " 25  Wind_Direction         category      \n",
      " 26  Wind_Speed(mph)        float64       \n",
      " 27  Precipitation(in)      float64       \n",
      " 28  Weather_Condition      category      \n",
      " 29  Amenity                bool          \n",
      " 30  Bump                   bool          \n",
      " 31  Crossing               bool          \n",
      " 32  Give_Way               bool          \n",
      " 33  Junction               bool          \n",
      " 34  No_Exit                bool          \n",
      " 35  Railway                bool          \n",
      " 36  Roundabout             bool          \n",
      " 37  Station                bool          \n",
      " 38  Stop                   bool          \n",
      " 39  Traffic_Calming        bool          \n",
      " 40  Traffic_Signal         bool          \n",
      " 41  Turning_Loop           bool          \n",
      " 42  Sunrise_Sunset         category      \n",
      " 43  Civil_Twilight         category      \n",
      " 44  Nautical_Twilight      category      \n",
      " 45  Astronomical_Twilight  category      \n",
      " 46  Start_Year             float64       \n",
      " 47  Start_Month            float64       \n",
      " 48  Start_Day              float64       \n",
      " 49  Start_DayOfWeek        float64       \n",
      " 50  Start_Hour             float64       \n",
      " 51  Start_Minute           float64       \n",
      " 52  Start_Second           float64       \n",
      " 53  Start_IsWeekend        int64         \n",
      " 54  End_Year               float64       \n",
      " 55  End_Month              float64       \n",
      " 56  End_Day                float64       \n",
      " 57  End_DayOfWeek          float64       \n",
      " 58  End_Hour               float64       \n",
      " 59  End_Minute             float64       \n",
      " 60  End_Second             float64       \n",
      " 61  End_IsWeekend          int64         \n",
      " 62  Duration_Minutes       float64       \n",
      " 63  Duration_Hours         float64       \n",
      "dtypes: bool(13), category(8), datetime64[ns](3), float64(28), int64(2), string(10)\n",
      "memory usage: 2.6 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd8c7ff-f397-4d8f-9cce-20dd406a7916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                         0\n",
      "Amenity                    0\n",
      "Bump                       0\n",
      "Give_Way                   0\n",
      "Junction                   0\n",
      "                      ...   \n",
      "Duration_Hours        743166\n",
      "Wind_Chill(F)        1999019\n",
      "Precipitation(in)    2203586\n",
      "End_Lat              3402762\n",
      "End_Lng              3402762\n",
      "Length: 64, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ee04a6-f1d9-44b8-9521-8b990a47154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End_Lat                  3402762\n",
      "End_Lng                  3402762\n",
      "Precipitation(in)        2203586\n",
      "Wind_Chill(F)            1999019\n",
      "Duration_Hours            743166\n",
      "End_Month                 743166\n",
      "Start_Day                 743166\n",
      "Start_Hour                743166\n",
      "Start_Minute              743166\n",
      "Start_Second              743166\n",
      "Start_Month               743166\n",
      "Start_DayOfWeek           743166\n",
      "End_Year                  743166\n",
      "End_Day                   743166\n",
      "End_DayOfWeek             743166\n",
      "End_Hour                  743166\n",
      "End_Minute                743166\n",
      "End_Second                743166\n",
      "Start_Year                743166\n",
      "End_Time                  743166\n",
      "Start_Time                743166\n",
      "Duration_Minutes          743166\n",
      "Wind_Speed(mph)           571233\n",
      "Visibility(mi)            177098\n",
      "Wind_Direction            175206\n",
      "Humidity(%)               174144\n",
      "Weather_Condition         173459\n",
      "Temperature(F)            163853\n",
      "Pressure(in)              140679\n",
      "Weather_Timestamp         120228\n",
      "Astronomical_Twilight      23246\n",
      "Nautical_Twilight          23246\n",
      "Civil_Twilight             23246\n",
      "Sunrise_Sunset             23246\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_summary = df.isnull().sum().sort_values(ascending=False)\n",
    "missing_summary = missing_summary[missing_summary > 0]\n",
    "print(missing_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5109b924-0a28-4234-b035-ce01c87b395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ No need for KNN imputation (all weather missingness <10%).\n",
      "✅ Hybrid imputation complete (target-safe).\n",
      "Remaining missing values:\n",
      " Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#=========================================\n",
    "# US Accidents Hybrid Imputation Pipeline (Final Version)\n",
    "# Target: Duration_Minutes / Duration_Hours\n",
    "#=========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#=========================================\n",
    "# 1. HANDLE HEAVY-MISSING COORDINATES\n",
    "#=========================================\n",
    "# >40% missing → cannot impute accurately\n",
    "# Option 1: fill with start coordinates (approximation)\n",
    "df['End_Lat'] = df['End_Lat'].fillna(df['Start_Lat'])\n",
    "df['End_Lng'] = df['End_Lng'].fillna(df['Start_Lng'])\n",
    "# Option 2: drop columns if not used later\n",
    "# df = df.drop(columns=['End_Lat', 'End_Lng'])\n",
    "\n",
    "#=========================================\n",
    "# 2. IMPUTE WEATHER FEATURES\n",
    "#=========================================\n",
    "weather_cols_all = [\n",
    "    'Temperature(F)', 'Humidity(%)', 'Pressure(in)',\n",
    "    'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)', 'Wind_Chill(F)'\n",
    "]\n",
    "\n",
    "# --- Step 2a: Simple groupwise median ---\n",
    "for col in weather_cols_all:\n",
    "    df[col] = df.groupby('State')[col].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# --- Step 2b: Selective KNN for highly-missing correlated numeric features (>10% missing) ---\n",
    "weather_for_knn = ['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)']\n",
    "missing_ratio = df[weather_for_knn].isna().mean()\n",
    "cols_for_knn = missing_ratio[missing_ratio > 0.10].index.tolist()\n",
    "\n",
    "if cols_for_knn:\n",
    "    print(f\"⚙️ Applying KNN imputation to: {cols_for_knn}\")\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(df[cols_for_knn])\n",
    "    knn = KNNImputer(n_neighbors=3, weights='uniform')\n",
    "    imputed_scaled = knn.fit_transform(scaled)\n",
    "    df[cols_for_knn] = scaler.inverse_transform(imputed_scaled)\n",
    "else:\n",
    "    print(\"✅ No need for KNN imputation (all weather missingness <10%).\")\n",
    "\n",
    "#=========================================\n",
    "# 3. CATEGORICAL FEATURES\n",
    "#=========================================\n",
    "cat_cols = [\n",
    "    'Wind_Direction', 'Weather_Condition',\n",
    "    'Sunrise_Sunset', 'Civil_Twilight',\n",
    "    'Nautical_Twilight', 'Astronomical_Twilight'\n",
    "]\n",
    "\n",
    "for col in cat_cols:\n",
    "    if df[col].isna().mean() > 0:\n",
    "        df[col] = df.groupby('State')[col].transform(\n",
    "            lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
    "        )\n",
    "\n",
    "#=========================================\n",
    "# 4. WEATHER TIMESTAMP\n",
    "#=========================================\n",
    "df = df.sort_values(['City', 'Start_Time'])\n",
    "df['Weather_Timestamp'] = df.groupby('City')['Weather_Timestamp'].ffill().bfill()\n",
    "\n",
    "#=========================================\n",
    "# 5. HANDLE DATETIME & TARGET (Duration) FIELDS\n",
    "#=========================================\n",
    "# Drop rows missing both Start_Time and End_Time\n",
    "df = df.dropna(subset=['Start_Time', 'End_Time'])\n",
    "\n",
    "# Recompute duration where both timestamps exist but Duration is missing\n",
    "mask = df['Duration_Minutes'].isna() & df['Start_Time'].notna() & df['End_Time'].notna()\n",
    "df.loc[mask, 'Duration_Minutes'] = (df.loc[mask, 'End_Time'] - df.loc[mask, 'Start_Time']).dt.total_seconds() / 60\n",
    "df.loc[mask, 'Duration_Hours'] = df.loc[mask, 'Duration_Minutes'] / 60\n",
    "\n",
    "# Drop any rows still missing target variable\n",
    "df = df.dropna(subset=['Duration_Minutes', 'Duration_Hours'])\n",
    "\n",
    "#=========================================\n",
    "# 6. RECOMPUTE DERIVED TIME FEATURES\n",
    "#=========================================\n",
    "df['Start_Year'] = df['Start_Time'].dt.year\n",
    "df['Start_Month'] = df['Start_Time'].dt.month\n",
    "df['Start_Day'] = df['Start_Time'].dt.day\n",
    "df['Start_DayOfWeek'] = df['Start_Time'].dt.dayofweek\n",
    "df['Start_Hour'] = df['Start_Time'].dt.hour\n",
    "df['Start_Minute'] = df['Start_Time'].dt.minute\n",
    "df['Start_Second'] = df['Start_Time'].dt.second\n",
    "df['Start_IsWeekend'] = (df['Start_DayOfWeek'] >= 5).astype(int)\n",
    "\n",
    "df['End_Year'] = df['End_Time'].dt.year\n",
    "df['End_Month'] = df['End_Time'].dt.month\n",
    "df['End_Day'] = df['End_Time'].dt.day\n",
    "df['End_DayOfWeek'] = df['End_Time'].dt.dayofweek\n",
    "df['End_Hour'] = df['End_Time'].dt.hour\n",
    "df['End_Minute'] = df['End_Time'].dt.minute\n",
    "df['End_Second'] = df['End_Time'].dt.second\n",
    "df['End_IsWeekend'] = (df['End_DayOfWeek'] >= 5).astype(int)\n",
    "\n",
    "#=========================================\n",
    "# 7. FINAL IMPUTATION PASS (Predictors only)\n",
    "#=========================================\n",
    "# Numeric predictors\n",
    "num_cols = [c for c in df.select_dtypes(include=['float64', 'int64']).columns\n",
    "            if c not in ['Duration_Minutes', 'Duration_Hours']]  # exclude targets\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df[num_cols] = imputer.fit_transform(df[num_cols])\n",
    "\n",
    "# Categorical predictors\n",
    "cat_cols_all = df.select_dtypes(include=['category', 'object', 'string']).columns\n",
    "for col in cat_cols_all:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "#=========================================\n",
    "# 8. FINAL CHECK\n",
    "#=========================================\n",
    "missing_summary = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"✅ Hybrid imputation complete (target-safe).\")\n",
    "print(\"Remaining missing values:\\n\", missing_summary[missing_summary > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63a46e30-11b6-4f10-a3f3-5ddf20503395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  0\n",
       "Source              0\n",
       "Severity            0\n",
       "Start_Time          0\n",
       "End_Time            0\n",
       "                   ..\n",
       "End_Minute          0\n",
       "End_Second          0\n",
       "End_IsWeekend       0\n",
       "Duration_Minutes    0\n",
       "Duration_Hours      0\n",
       "Length: 64, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d08e5c2-97c5-4ee3-92c2-0b3217811a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping 'ID' (6985228 categories) — too many unique values\n",
      "⚠️ Skipping 'Description' (3542610 categories) — too many unique values\n",
      "⚠️ Skipping 'Street' (319545 categories) — too many unique values\n",
      "⚠️ Skipping 'City' (13593 categories) — too many unique values\n",
      "⚠️ Skipping 'County' (1822 categories) — too many unique values\n",
      "⚠️ Skipping 'State' (49 categories) — too many unique values\n",
      "⚠️ Skipping 'Zipcode' (771885 categories) — too many unique values\n",
      "✅ Encoded 3 categorical columns successfully.\n",
      "✅ Final dataset shape: (6985228, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>Weather_Timestamp</th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Wind_Chill(F)</th>\n",
       "      <th>...</th>\n",
       "      <th>Duration_Hours</th>\n",
       "      <th>Source_Source2</th>\n",
       "      <th>Source_Source3</th>\n",
       "      <th>Severity_2</th>\n",
       "      <th>Severity_3</th>\n",
       "      <th>Severity_4</th>\n",
       "      <th>Timezone_USEastern</th>\n",
       "      <th>Timezone_USMountain</th>\n",
       "      <th>Timezone_USPacific</th>\n",
       "      <th>Timezone_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2796054</th>\n",
       "      <td>2018-05-06 19:08:26</td>\n",
       "      <td>2018-05-06 19:38:12</td>\n",
       "      <td>40.905312</td>\n",
       "      <td>-77.421593</td>\n",
       "      <td>40.905312</td>\n",
       "      <td>-77.421593</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2018-05-06 18:53:00</td>\n",
       "      <td>51.8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496111</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390565</th>\n",
       "      <td>2018-12-17 07:50:05</td>\n",
       "      <td>2018-12-17 08:19:12</td>\n",
       "      <td>40.883820</td>\n",
       "      <td>-77.467682</td>\n",
       "      <td>40.883820</td>\n",
       "      <td>-77.467682</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2018-12-17 06:53:00</td>\n",
       "      <td>35.6</td>\n",
       "      <td>29.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485278</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7718870</th>\n",
       "      <td>2019-08-04 00:09:11</td>\n",
       "      <td>2019-08-04 00:38:29</td>\n",
       "      <td>40.905501</td>\n",
       "      <td>-77.419572</td>\n",
       "      <td>40.904403</td>\n",
       "      <td>-77.401810</td>\n",
       "      <td>0.931</td>\n",
       "      <td>2019-08-04 00:16:00</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7718871</th>\n",
       "      <td>2019-08-04 00:09:11</td>\n",
       "      <td>2019-08-04 00:38:29</td>\n",
       "      <td>40.904403</td>\n",
       "      <td>-77.401810</td>\n",
       "      <td>40.905501</td>\n",
       "      <td>-77.419572</td>\n",
       "      <td>0.931</td>\n",
       "      <td>2019-08-04 00:16:00</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402241</th>\n",
       "      <td>2020-08-05 18:18:34</td>\n",
       "      <td>2020-08-05 21:54:51</td>\n",
       "      <td>40.904720</td>\n",
       "      <td>-77.388947</td>\n",
       "      <td>40.904720</td>\n",
       "      <td>-77.388947</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2020-08-05 17:53:00</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.604722</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Start_Time            End_Time  Start_Lat  Start_Lng  \\\n",
       "2796054 2018-05-06 19:08:26 2018-05-06 19:38:12  40.905312 -77.421593   \n",
       "2390565 2018-12-17 07:50:05 2018-12-17 08:19:12  40.883820 -77.467682   \n",
       "7718870 2019-08-04 00:09:11 2019-08-04 00:38:29  40.905501 -77.419572   \n",
       "7718871 2019-08-04 00:09:11 2019-08-04 00:38:29  40.904403 -77.401810   \n",
       "1402241 2020-08-05 18:18:34 2020-08-05 21:54:51  40.904720 -77.388947   \n",
       "\n",
       "           End_Lat    End_Lng  Distance(mi)   Weather_Timestamp  \\\n",
       "2796054  40.905312 -77.421593         0.000 2018-05-06 18:53:00   \n",
       "2390565  40.883820 -77.467682         0.000 2018-12-17 06:53:00   \n",
       "7718870  40.904403 -77.401810         0.931 2019-08-04 00:16:00   \n",
       "7718871  40.905501 -77.419572         0.931 2019-08-04 00:16:00   \n",
       "1402241  40.904720 -77.388947         0.000 2020-08-05 17:53:00   \n",
       "\n",
       "         Temperature(F)  Wind_Chill(F)  ...  Duration_Hours  Source_Source2  \\\n",
       "2796054            51.8           48.0  ...        0.496111            True   \n",
       "2390565            35.6           29.2  ...        0.485278            True   \n",
       "7718870            67.0           67.0  ...        0.488333           False   \n",
       "7718871            67.0           67.0  ...        0.488333           False   \n",
       "1402241            81.0           81.0  ...        3.604722            True   \n",
       "\n",
       "         Source_Source3  Severity_2  Severity_3  Severity_4  \\\n",
       "2796054           False        True       False       False   \n",
       "2390565           False        True       False       False   \n",
       "7718870           False       False        True       False   \n",
       "7718871           False       False        True       False   \n",
       "1402241           False        True       False       False   \n",
       "\n",
       "         Timezone_USEastern  Timezone_USMountain  Timezone_USPacific  \\\n",
       "2796054                True                False               False   \n",
       "2390565                True                False               False   \n",
       "7718870                True                False               False   \n",
       "7718871                True                False               False   \n",
       "1402241                True                False               False   \n",
       "\n",
       "         Timezone_Unknown  \n",
       "2796054             False  \n",
       "2390565             False  \n",
       "7718870             False  \n",
       "7718871             False  \n",
       "1402241             False  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Let’s build a clean, automated encoding pipeline that:\n",
    "\n",
    "Selects all categorical columns from your DataFrame.\n",
    "\n",
    "Counts the number of unique categories in each.\n",
    "\n",
    "Applies:\n",
    "\n",
    "One-Hot Encoding for binary (2-category) columns.\n",
    "\n",
    "Dummy Encoding (OHE with drop_first=True) for columns with >2 categories.\n",
    "\n",
    "Combines all encoded features into a new DataFrame encoded_df.\n",
    "\n",
    "Compares original vs encoded columns and identifies reference categories (the one dropped in dummy encoding).\n",
    "'''\n",
    "def encode_categorical_features_safe(df, max_unique=20):\n",
    "    \"\"\"\n",
    "    Safely encode categorical features in a DataFrame.\n",
    "\n",
    "    Rules:\n",
    "    - Skips columns with '_' in the name (engineered features)\n",
    "    - Skips columns with only 0–1 unique values\n",
    "    - Skips columns with > max_unique categories (too large for OHE)\n",
    "    - One-hot encodes binary categorical columns (2 unique values)\n",
    "    - Dummy encodes multi-class categorical columns (>2 and <= max_unique)\n",
    "    \n",
    "    Returns:\n",
    "        encoded_df: encoded categorical features (numeric)\n",
    "        ref_df: reference summary with dropped categories\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    encoded_dfs = []\n",
    "    reference_summary = []\n",
    "\n",
    "    # 1️⃣ Select categorical and string columns\n",
    "    cat_cols = df.select_dtypes(include=['category', 'object', 'string']).columns\n",
    "    cat_cols = [col for col in cat_cols if '_' not in col]\n",
    "\n",
    "    if len(cat_cols) == 0:\n",
    "        print(\"⚠️ No categorical columns found for encoding.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # 2️⃣ Iterate columns\n",
    "    for col in cat_cols:\n",
    "        n_unique = df[col].nunique(dropna=True)\n",
    "        if n_unique <= 1:\n",
    "            reference_summary.append({\n",
    "                'Column': col, 'Unique_Categories': n_unique,\n",
    "                'Encoding_Type': 'Skipped (constant)', 'Reference_Category': None\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        elif n_unique > max_unique:\n",
    "            print(f\"⚠️ Skipping '{col}' ({n_unique} categories) — too many unique values\")\n",
    "            reference_summary.append({\n",
    "                'Column': col, 'Unique_Categories': n_unique,\n",
    "                'Encoding_Type': 'Skipped (high-cardinality)', 'Reference_Category': None\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # One-hot or dummy encoding\n",
    "        if n_unique == 2:\n",
    "            encoded = pd.get_dummies(df[col], prefix=col, drop_first=False)\n",
    "            ref_value = None\n",
    "            encoding_type = 'One-Hot'\n",
    "        else:\n",
    "            encoded = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "            ref_value = sorted(df[col].dropna().unique())[0]\n",
    "            encoding_type = 'Dummy'\n",
    "\n",
    "        encoded_dfs.append(encoded)\n",
    "        reference_summary.append({\n",
    "            'Column': col,\n",
    "            'Unique_Categories': n_unique,\n",
    "            'Encoding_Type': encoding_type,\n",
    "            'Reference_Category': ref_value\n",
    "        })\n",
    "\n",
    "    # 3️⃣ Combine encoded features\n",
    "    encoded_df = pd.concat(encoded_dfs, axis=1) if encoded_dfs else pd.DataFrame()\n",
    "    ref_df = pd.DataFrame(reference_summary)\n",
    "\n",
    "    print(f\"✅ Encoded {len(encoded_dfs)} categorical columns successfully.\")\n",
    "    return encoded_df, ref_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "encoded_df, ref_df = encode_categorical_features_safe(df, max_unique=20)\n",
    "\n",
    "# Keep numeric / boolean columns\n",
    "non_cat_df = df.select_dtypes(exclude=['category', 'object', 'string'])\n",
    "\n",
    "# Merge into final modeling dataset\n",
    "final_df = pd.concat([non_cat_df, encoded_df], axis=1)\n",
    "\n",
    "print(f\"✅ Final dataset shape: {final_df.shape}\")\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf3de715-9ea2-429f-8507-c1cb53ce6bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Unique_Categories</th>\n",
       "      <th>Encoding_Type</th>\n",
       "      <th>Reference_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>6985228</td>\n",
       "      <td>Skipped (high-cardinality)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Source</td>\n",
       "      <td>3</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>Source1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Severity</td>\n",
       "      <td>4</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Description</td>\n",
       "      <td>3542610</td>\n",
       "      <td>Skipped (high-cardinality)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Street</td>\n",
       "      <td>319545</td>\n",
       "      <td>Skipped (high-cardinality)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>City</td>\n",
       "      <td>13593</td>\n",
       "      <td>Skipped (high-cardinality)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>County</td>\n",
       "      <td>1822</td>\n",
       "      <td>Skipped (high-cardinality)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>State</td>\n",
       "      <td>49</td>\n",
       "      <td>Skipped (high-cardinality)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zipcode</td>\n",
       "      <td>771885</td>\n",
       "      <td>Skipped (high-cardinality)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Country</td>\n",
       "      <td>1</td>\n",
       "      <td>Skipped (constant)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Timezone</td>\n",
       "      <td>5</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>USCentral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column  Unique_Categories               Encoding_Type  \\\n",
       "0            ID            6985228  Skipped (high-cardinality)   \n",
       "1        Source                  3                       Dummy   \n",
       "2      Severity                  4                       Dummy   \n",
       "3   Description            3542610  Skipped (high-cardinality)   \n",
       "4        Street             319545  Skipped (high-cardinality)   \n",
       "5          City              13593  Skipped (high-cardinality)   \n",
       "6        County               1822  Skipped (high-cardinality)   \n",
       "7         State                 49  Skipped (high-cardinality)   \n",
       "8       Zipcode             771885  Skipped (high-cardinality)   \n",
       "9       Country                  1          Skipped (constant)   \n",
       "10     Timezone                  5                       Dummy   \n",
       "\n",
       "   Reference_Category  \n",
       "0                None  \n",
       "1             Source1  \n",
       "2                   1  \n",
       "3                None  \n",
       "4                None  \n",
       "5                None  \n",
       "6                None  \n",
       "7                None  \n",
       "8                None  \n",
       "9                None  \n",
       "10          USCentral  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ff4bd6b-963d-4b7c-9632-467f3187fa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6985228 entries, 2796054 to 3679722\n",
      "Data columns (total 55 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   Start_Time           datetime64[ns]\n",
      " 1   End_Time             datetime64[ns]\n",
      " 2   Start_Lat            float64       \n",
      " 3   Start_Lng            float64       \n",
      " 4   End_Lat              float64       \n",
      " 5   End_Lng              float64       \n",
      " 6   Distance(mi)         float64       \n",
      " 7   Weather_Timestamp    datetime64[ns]\n",
      " 8   Temperature(F)       float64       \n",
      " 9   Wind_Chill(F)        float64       \n",
      " 10  Humidity(%)          float64       \n",
      " 11  Pressure(in)         float64       \n",
      " 12  Visibility(mi)       float64       \n",
      " 13  Wind_Speed(mph)      float64       \n",
      " 14  Precipitation(in)    float64       \n",
      " 15  Amenity              bool          \n",
      " 16  Bump                 bool          \n",
      " 17  Crossing             bool          \n",
      " 18  Give_Way             bool          \n",
      " 19  Junction             bool          \n",
      " 20  No_Exit              bool          \n",
      " 21  Railway              bool          \n",
      " 22  Roundabout           bool          \n",
      " 23  Station              bool          \n",
      " 24  Stop                 bool          \n",
      " 25  Traffic_Calming      bool          \n",
      " 26  Traffic_Signal       bool          \n",
      " 27  Turning_Loop         bool          \n",
      " 28  Start_Year           int32         \n",
      " 29  Start_Month          int32         \n",
      " 30  Start_Day            int32         \n",
      " 31  Start_DayOfWeek      int32         \n",
      " 32  Start_Hour           int32         \n",
      " 33  Start_Minute         int32         \n",
      " 34  Start_Second         int32         \n",
      " 35  Start_IsWeekend      float64       \n",
      " 36  End_Year             int32         \n",
      " 37  End_Month            int32         \n",
      " 38  End_Day              int32         \n",
      " 39  End_DayOfWeek        int32         \n",
      " 40  End_Hour             int32         \n",
      " 41  End_Minute           int32         \n",
      " 42  End_Second           int32         \n",
      " 43  End_IsWeekend        float64       \n",
      " 44  Duration_Minutes     float64       \n",
      " 45  Duration_Hours       float64       \n",
      " 46  Source_Source2       bool          \n",
      " 47  Source_Source3       bool          \n",
      " 48  Severity_2           bool          \n",
      " 49  Severity_3           bool          \n",
      " 50  Severity_4           bool          \n",
      " 51  Timezone_USEastern   bool          \n",
      " 52  Timezone_USMountain  bool          \n",
      " 53  Timezone_USPacific   bool          \n",
      " 54  Timezone_Unknown     bool          \n",
      "dtypes: bool(22), datetime64[ns](3), float64(16), int32(14)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c8cbea8-6942-41a4-a841-2efc186a21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to pickle \n",
    "\n",
    "final_df.to_pickle(\"final_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeadd68-8639-487a-b457-0f9b68007b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
